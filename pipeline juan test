# Simple CI/CD Pipeline for GCP Cloud Run

## Prerequisites
- GCP Project with billing enabled
- GitHub repository
- Local `gcloud` CLI installed

## Step 1: GCP Setup (5 minutes)

### 1.1 Set Project and Enable APIs
```bash
# Set your project ID
export PROJECT_ID="your-project-id"
gcloud config set project $PROJECT_ID

# Enable required services
gcloud services enable cloudbuild.googleapis.com run.googleapis.com artifactregistry.googleapis.com
```

### 1.2 Create Artifact Registry
```bash
gcloud artifacts repositories create topdoc \
    --repository-format=docker \
    --location=us-central1
```

https://console.cloud.google.com/artifacts?referrer=search&authuser=1&inv=1&invt=Ab0WRw&project=supernova-868a0



### 1.3 Create Service Account
```bash
# Create service account
gcloud iam service-accounts create github-actions

# Add permissions
gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:github-actions@$PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/artifactregistry.writer"

gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:github-actions@$PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/run.admin"

gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:github-actions@$PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/iam.serviceAccountUser"

# Create key
gcloud iam service-accounts keys create key.json \
    --iam-account=github-actions@$PROJECT_ID.iam.gserviceaccount.com

# Show key content (copy this for GitHub)
cat key.json
```

## Step 2: Create Production Dockerfile

```dockerfile
# filepath: Dockerfile.prod
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy source and build
COPY . .
RUN npm run build

EXPOSE 8080

CMD ["node", "dist/index.js"]
```

## Step 3: Update package.json

```json
{
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js"
  }
}
```

## Step 4: GitHub Secrets

Go to your GitHub repo → Settings → Secrets → Actions, add:

- **Name:** `GCP_PROJECT_ID` **Value:** `your-project-id`
- **Name:** `GCP_SA_KEY` **Value:** `paste the entire key.json content here`

## Step 5: Create GitHub Actions

```yaml
# filepath: .github/workflows/deploy.yml
name: Deploy to Cloud Run

on:
  push:
    branches: [ main ]

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  SERVICE: topdoc-api
  REGION: us-central1

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Cloud SDK
      uses: google-github-actions/setup-gcloud@v0
      with:
        project_id: ${{ secrets.GCP_PROJECT_ID }}
        service_account_key: ${{ secrets.GCP_SA_KEY }}
        export_default_credentials: true
    
    - name: Configure Docker
      run: gcloud auth configure-docker us-central1-docker.pkg.dev
    
    - name: Build Docker Image
      run: |
        docker build -f Dockerfile.prod -t us-central1-docker.pkg.dev/$PROJECT_ID/topdoc/$SERVICE:$GITHUB_SHA .
        docker push us-central1-docker.pkg.dev/$PROJECT_ID/topdoc/$SERVICE:$GITHUB_SHA
    
    - name: Deploy to Cloud Run
      run: |
        gcloud run deploy $SERVICE \
          --image us-central1-docker.pkg.dev/$PROJECT_ID/topdoc/$SERVICE:$GITHUB_SHA \
          --region $REGION \
          --allow-unauthenticated \
          --set-env-vars="PORT=8080,MAX_RETRIES=3" \
          --memory=512Mi \
          --cpu=1 \
          --min-instances=0 \
          --max-instances=10
```

## Step 6: Update Config for Production

```typescript
# filepath: src/config.ts
export const MAX_RETRIES = parseInt(process.env.MAX_RETRIES || '3');
export const PORT = parseInt(process.env.PORT || '8080'); // Cloud Run uses 8080

export const REDIS_CONFIG = {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT || '6379'),
};
```

## Step 7: Test the Pipeline

1. **Push to main branch:**
```bash
git add .
git commit -m "Add CI/CD pipeline"
git push origin main
```

2. **Watch GitHub Actions:**
   - Go to your repo → Actions tab
   - See the deployment progress

3. **Get your app URL:**
```bash
gcloud run services describe topdoc-api --region=us-central1 --format="value(status.url)"
```

## Step 8: Test Your Deployed API

```bash
# Replace YOUR_CLOUD_RUN_URL with the actual URL

https://topdoc-api-260193173549.us-central1.run.app

curl -X POST https://YOUR_CLOUD_RUN_URL/lab-results \
  -H "Content-Type: application/json" \
  -d '{
    "patientId": "12345",
    "labType": "blood", 
    "result": "positive",
    "receivedAt": "2025-10-07T10:00:00Z"
  }'
```

## Optional: Add Redis to Production

```bash
# Create Redis instance
gcloud redis instances create topdoc-redis \
    --size=1 \
    --region=us-central1

# Get Redis IP
gcloud redis instances describe topdoc-redis --region=us-central1 --format="value(host)"

# Update Cloud Run with Redis


gcloud run services update topdoc-api \
    --region=us-central1 \
    --set-env-vars="REDIS_HOST=10.254.141.75"

## That's it! 

**Your pipeline now:**
- ✅ Builds on every push to main-
- ✅ Deploys to Cloud Run automatically  
- ✅ Uses secure service account
- ✅ Stores images in Artifact Registry
- ✅ Scales automatically (0-10 instances)

**Total setup time: ~10 minutes**




fixex por no conectividad a redis

# Create subnet with /28 netmask (16 IP addresses)
gcloud compute networks subnets create topdoc-connector-subnet \
    --network=default \
    --range=10.8.0.0/28 \
    --region=us-central1

# Create VPC connector to access Redis private network
gcloud compute networks vpc-access connectors create topdoc-connector \
    --region=us-central1 \
    --subnet=default \
    --min-instances=2 \
    --max-instances=3




gcloud run services update topdoc-api \
    --region=us-central1 \
    --vpc-connector=topdoc-connector \
    --set-env-vars="REDIS_HOST=10.254.141.75"